{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# !!! REMEMBER YOUR BUCKET !!!\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "        \n",
    "# Setup\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('sagemaker-demo-cobus')\n",
    "bucket.load()\n",
    "prefix = 'sample_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "import pickle, gzip, urllib.request, json\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "print(train_set[0].shape)\n",
    "print(valid_set[0].shape)\n",
    "print(test_set[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2,10)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    img = train_set[0][i]\n",
    "    label = train_set[1][i]\n",
    "    img_reshape = img.reshape((28,28))\n",
    "    imgplot = plt.imshow(img_reshape, cmap='gray')\n",
    "    #print('This is a {}'.format(label))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import struct\n",
    "import io\n",
    "import csv\n",
    "import boto3\n",
    "        \n",
    "def convert_data():\n",
    "    print('Loaded bucket {}'.format(bucket.name))\n",
    "    \n",
    "    data_partitions = [('train', train_set), ('validation', valid_set), ('test', test_set)]\n",
    "    for data_partition_name, data_partition in data_partitions:\n",
    "        print('{}: {} {}'.format(data_partition_name, data_partition[0].shape, data_partition[1].shape))\n",
    "        labels = [t.tolist() for t in data_partition[1]]\n",
    "        features = [t.tolist() for t in data_partition[0]]\n",
    "        \n",
    "        if data_partition_name != 'test':\n",
    "            examples = np.insert(features, 0, labels, axis=1)\n",
    "        else:\n",
    "            examples = features\n",
    "        \n",
    "        \n",
    "        np.savetxt('data.csv', examples, delimiter=',')\n",
    "        \n",
    "        key = \"{}/{}/examples\".format(prefix,data_partition_name)\n",
    "        url = 's3://{}/{}'.format(bucket.name, key)\n",
    "        print('Saving to url {}'.format(url))\n",
    "        bucket.Object(key).upload_file('data.csv')\n",
    "        print('Done writing to {}'.format(url))\n",
    "\n",
    "convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n",
    "train_data = 's3://{}/{}/{}'.format(bucket.name, prefix, 'train')\n",
    "validation_data = 's3://{}/{}/{}'.format(bucket.name, prefix, 'validation')\n",
    "\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket.name, prefix, 'xgboost_model_sdk')\n",
    "print(s3_output_location)\n",
    "\n",
    "xgb_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         train_volume_size = 5,\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session())\n",
    "\n",
    "xgb_model.set_hyperparameters(max_depth = 5,\n",
    "                              eta = .2,\n",
    "                              gamma = 4,\n",
    "                              min_child_weight = 6,\n",
    "                              silent = 0,\n",
    "                              objective = \"multi:softmax\",\n",
    "                              num_class = 10,\n",
    "                              num_round = 10)\n",
    "\n",
    "train_channel = sagemaker.session.s3_input(train_data, content_type='text/csv')\n",
    "valid_channel = sagemaker.session.s3_input(validation_data, content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': valid_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels,  logs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                                instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def validate_model():\n",
    "    test_key = \"{}/test/examples\".format(prefix)\n",
    "    bucket.download_file(test_key, 'test_data')\n",
    "    \n",
    "    %matplotlib inline\n",
    "                        \n",
    "    for i in range (0, 10):\n",
    "        img = test_set[0][i]\n",
    "        label = test_set[1][i]\n",
    "        img_reshape = img.reshape((28,28))\n",
    "        imgplot = plt.imshow(img_reshape, cmap='gray')\n",
    "        print('This is a {}'.format(label))\n",
    "        plt.show()\n",
    "        \n",
    "    with open('test_data', 'r') as f:\n",
    "        for j in range(0,10):\n",
    "            single_test = f.readline()\n",
    "            result = xgb_predictor.predict(single_test)\n",
    "            print(result)\n",
    "            \n",
    "validate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
